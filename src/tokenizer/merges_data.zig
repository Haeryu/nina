// ⚠️ This file is autogenerated. Do not modify directly.
// Generated by export_tokenizer_zig.py

pub const merges_data = [_]struct { []const u8, []const u8 }{
    .{ "Ä", "Ä" },
    .{ "a", "r" },
    .{ "e", "l" },
    .{ "h", "i" },
    .{ "h", "o" },
    .{ "h", "el" },
    .{ "l", "o" },
    .{ "o", "u" },
    .{ "y", "ou" },
    .{ "Ä ", "ar" },
    .{ "Ä ", "you" },
    .{ "ho", "w" },
    .{ "hel", "lo" },
    .{ "Ä ar", "e" },
};
